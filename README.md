# ğŸ’³ Credit Card Fraud Detection â€” Public Project Preview (Business-Oriented ML)

This is a **public showcase** of my finalâ€‘year BSc Computer Science project: a **credit card fraud detection** system built with machine learning and evaluated with a **business / risk** mindset (metrics â†’ decisions â†’ operational impact).

> ğŸ” The full endâ€‘toâ€‘end implementation (weekâ€‘byâ€‘week reports, experiment logs, full scorecards, models) is currently in a **private repository** and can be shared on request (academic evaluation / recruitment).

---

## ğŸ§­ Executive Summary

Fraud detection is a **rare-event classification** problem where accuracy is misleading. The practical goal is to:

- **Stop fraud** (high **Recall/Fraud**, reduce fraud leakage)
- Keep **false alarms** operationally acceptable (reasonable **Precision/Fraud**, reduce customer friction + analyst workload)
- Treat the classification threshold as an **operational policy** (not â€œ0.5 by defaultâ€)

---

## ğŸ¦ Business translation (how we read the metrics)

- **TP (True Positives)** â†’ frauds stopped
- **FN (False Negatives)** â†’ frauds missed (financial loss / risk)
- **FP (False Positives)** â†’ false alarms (manual review cost + customer friction)

Threshold tuning is performed with a **cost-sensitive policy** (example: `cost_fp=1`, `cost_fn=20`) and selected on validation, then applied to test.

---

## ğŸ“Š Dataset (Summary)

- Classic anonymized credit card fraud dataset (Kaggle / ULB-style)
- ~285k transactions, ~0.17% fraud rate (extreme class imbalance)
- Features: `V1..V28` (PCA components) + `Amount` + `Time`
- Target: `Class` (0 = legitimate, 1 = fraud)

âœ… Raw data is **not included** in this public repo.

---

## ğŸ“ˆ Public Snapshot (XGBoost + Business Threshold Policy)

The model is evaluated using PRâ€‘AUC (more informative under class imbalance), and a validationâ€‘selected operating threshold is applied to the test set.

**XGBoost (test, threshold â‰ˆ 0.0884):**
- Precision(Fraud) â‰ˆ **0.794**
- Recall(Fraud) â‰ˆ **0.811**
- PRâ€‘AUC â‰ˆ **0.817**
- Confusion (business view): **TP=77**, **FN=18**, **FP=20**, **TN=56631**

Interpretation:
- We stop **77** fraud transactions in the test set.
- We miss **18** frauds (leakage).
- We raise **20** false alarms (review/customer friction).

---

## ğŸ–¼ï¸ Visual Preview (Key Business Figures)

### Precisionâ€“Recall Curve (Imbalanced KPI)
![PR Curve â€” XGBoost](figures/week12_xgb_pr_test.png)

### Cost vs Threshold (Policy Selection)
![Cost vs Threshold â€” XGBoost](figures/week12_xgb_cost_vs_threshold_test.png)

### Confusion Matrix (Business Impact)
![Confusion Matrix â€” XGBoost](figures/week12_xgb_cm_test.png)

---

## ğŸ§± High-level System Design (Private repo)

The full project is structured as a modular ML system:

- `src/` â€“ training & evaluation scripts (pipeline style)
- `reports/` â€“ week-by-week markdown + auditable artifacts (JSON/CSV)
- `models/` â€“ saved models (`.joblib`)
- Planned (Month 4):
  - Interpretability (feature importance + SHAP-style explanations)
  - REST API `/predict` + lightweight dashboard
  - Optional Docker packaging

---

## ğŸ› ï¸ Tools & Technologies

Python â€¢ pandas â€¢ NumPy â€¢ scikitâ€‘learn â€¢ XGBoost â€¢ Matplotlib â€¢ Git/GitHub

---

## ğŸ‘¤ Author

**Lazaros Voulistiotis**  
BSc Computer Science (Final Year) â€” Thesis Project  
Aspiring Machine Learning Engineer

(LinkedIn link available in GitHub bio)

---

## ğŸ“ Notes

- This public repository is intentionally lightweight (overview + selected figures).
- Raw dataset and full run artifacts are excluded from version control.
